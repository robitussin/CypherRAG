{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from generate_graph import get_propositions, generateEdges, createGraph, get_propositions_nosplit\n",
    "from query_graph import QueryGraph\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('datasets/HotPotQA/hotpot_dev_distractor_v1.json')\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the evaluation script\n",
    "\n",
    "```\n",
    "python hotpot_evaluate_v1.py <path_to_prediction> <path_to_gold>\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "python hotpot_evaluate_v1.py <sample_dev_pred.json> <hotpot_dev_fullwiki_v1.json>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_list = df['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(context_list[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# propositions = []\n",
    "\n",
    "# for i, value in enumerate(tqdm(context_list[0:2])):\n",
    "#         for j, context in enumerate(value):\n",
    "#                 index = 1\n",
    "#                 if index < len(context):\n",
    "#                     words = context[1]\n",
    "#                     combined = \" \".join(words)\n",
    "#                     get_propositions_nosplit(combined, propositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the file in read mode\n",
    "# with open('propositions.txt', 'r') as file:\n",
    "#     # Read all lines and store them in a list\n",
    "#     propositions_from_file = [line.strip() for line in file]\n",
    "\n",
    "# print(propositions_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_edges = generateEdges(propositions_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if createGraph(list_of_edges):\n",
    "#     print(\"Success\")\n",
    "# else:\n",
    "#     print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_supporting_facts(question, answer, context):\n",
    "#     supporting_facts = []\n",
    "#     for passage in context:\n",
    "#         title, sentences = passage\n",
    "#         for i, sentence in enumerate(sentences):\n",
    "#             if answer in sentence or any(word in sentence for word in question.split()):\n",
    "#                 supporting_facts.append([title, i])\n",
    "#     return supporting_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to apply to each row\n",
    "# def print_qa(row):\n",
    "    \n",
    "#     question = row['question']\n",
    "#     questionid = row['_id']\n",
    "#     result = query_graph_cot(question)\n",
    "\n",
    "#     if result is not None:\n",
    "    \n",
    "#         model_answer = result['result']\n",
    "\n",
    "#         if \"don't know the answer\" in model_answer:\n",
    "#             model_answer = \"\"\n",
    "    \n",
    "#         if len(row['answer']) > 0:\n",
    "#             real_answer = row['answer']\n",
    "#         else:\n",
    "#             real_answer = \"\\\"\\\"\"\n",
    "\n",
    "#         if len(result['intermediate_steps']) > 0:\n",
    "#             cypher_query = result['intermediate_steps'][0]['query']\n",
    "#             context = result['intermediate_steps'][1]['context']\n",
    "       \n",
    "#             if(len(context) < 1):\n",
    "#             #     result = refine_query(cypher_query[6:], question)\n",
    "#             #     model_answer = result['result'] \n",
    "#                 model_answer = \"\\\"\\\"\"\n",
    "#                 my_dict.update({questionid: \"\"})\n",
    "#             else:\n",
    "#                 my_dict.update({questionid: model_answer})\n",
    "                \n",
    "#         with open(\"preds.txt\", \"a\") as preds:\n",
    "#             preds.write(\"question: \" + question + \"\\n\")\n",
    "#             preds.write(\"real_answer: \" + real_answer + \"\\n\")\n",
    "#             preds.write(\"model_answer: \" + model_answer + \"\\n\")  \n",
    "#             preds.write(\"cypher_query: \" + cypher_query + \"\\n\")\n",
    "#             preds.write(\"======================\" + \"\\n\")  \n",
    "#         preds.close()\n",
    "\n",
    "#     else: \n",
    "#         my_dict.update({questionid: \"\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dict = {}\n",
    "# # Apply the function to each row\n",
    "# df[0:2].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "# with open(\"dev_fullwiki_pred.json\", \"a\") as json_file:\n",
    "#     json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg = QueryGraph()\n",
    "\n",
    "QUERY = \"\"\"\n",
    "MATCH (N) RETURN N\n",
    "\"\"\"\n",
    "res = qg._graph.query(QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphmaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
