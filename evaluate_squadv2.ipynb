{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not connect to Neo4j database. Please ensure that the url is correct",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_async_compat/network/_bolt_socket.py:528\u001b[0m, in \u001b[0;36mBoltSocket._connect\u001b[0;34m(cls, resolved_address, timeout, keep_alive)\u001b[0m\n\u001b[1;32m    527\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  C: <OPEN> \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, resolved_address)\n\u001b[0;32m--> 528\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m s\u001b[38;5;241m.\u001b[39msettimeout(t)\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_async_compat/network/_bolt_socket.py:690\u001b[0m, in \u001b[0;36mBoltSocket.connect\u001b[0;34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mBoltSocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m     s \u001b[38;5;241m=\u001b[39m BoltSocket\u001b[38;5;241m.\u001b[39m_secure(s, resolved_address\u001b[38;5;241m.\u001b[39m_host_name,\n\u001b[1;32m    693\u001b[0m                            ssl_context)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_async_compat/network/_bolt_socket.py:546\u001b[0m, in \u001b[0;36mBoltSocket._connect\u001b[0;34m(cls, resolved_address, timeout, keep_alive)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish connection to \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m (reason \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(resolved_address, error)\n\u001b[1;32m    549\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [Errno 61] Connection refused)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/langchain_community/graphs/neo4j_graph.py:370\u001b[0m, in \u001b[0;36mNeo4jGraph.__init__\u001b[0;34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_connectivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mServiceUnavailable:\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/driver.py:1025\u001b[0m, in \u001b[0;36mDriver.verify_connectivity\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m   1024\u001b[0m session_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_session_config(config)\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/driver.py:1236\u001b[0m, in \u001b[0;36mDriver._get_server_info\u001b[0;34m(self, session_config)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session(session_config) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m-> 1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/work/session.py:172\u001b[0m, in \u001b[0;36mSession._get_server_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_ACCESS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m server_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mserver_info\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/work/session.py:130\u001b[0m, in \u001b[0;36mSession._connect\u001b[0;34m(self, access_mode, **acquire_kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43macquire_kwargs\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/work/workspace.py:178\u001b[0m, in \u001b[0;36mWorkspace._connect\u001b[0;34m(self, access_mode, auth, **acquire_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m acquire_kwargs_\u001b[38;5;241m.\u001b[39mupdate(acquire_kwargs)\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43macquire_kwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_access_mode \u001b[38;5;241m=\u001b[39m access_mode\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:526\u001b[0m, in \u001b[0;36mBoltPool.acquire\u001b[0;34m(self, access_mode, timeout, database, bookmarks, auth, liveness_check_timeout)\u001b[0m\n\u001b[1;32m    525\u001b[0m deadline \u001b[38;5;241m=\u001b[39m Deadline\u001b[38;5;241m.\u001b[39mfrom_timeout_or_deadline(timeout)\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:313\u001b[0m, in \u001b[0;36mIOPool._acquire\u001b[0;34m(self, address, auth, deadline, liveness_check_timeout)\u001b[0m\n\u001b[1;32m    312\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <POOL> trying to hand out new connection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:163\u001b[0m, in \u001b[0;36mIOPool._acquire_new_later.<locals>.connection_creator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ServiceUnavailable:\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:500\u001b[0m, in \u001b[0;36mBoltPool.open.<locals>.opener\u001b[0;34m(addr, auth_manager, deadline)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopener\u001b[39m(addr, auth_manager, deadline):\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBolt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrouting_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_sync/io/_bolt.py:401\u001b[0m, in \u001b[0;36mBolt.open\u001b[0;34m(cls, address, auth_manager, deadline, routing_context, pool_config)\u001b[0m\n\u001b[1;32m    398\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m Deadline(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    400\u001b[0m s, protocol_version, handshake, data \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 401\u001b[0m     \u001b[43mBoltSocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_resolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m pool_config\u001b[38;5;241m.\u001b[39mprotocol_version \u001b[38;5;241m=\u001b[39m protocol_version\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/neo4j/_async_compat/network/_bolt_socket.py:718\u001b[0m, in \u001b[0;36mBoltSocket.connect\u001b[0;34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (resolved to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    720\u001b[0m             \u001b[38;5;28mstr\u001b[39m(address), \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, resolved_addresses)),\n\u001b[1;32m    721\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, errors))\n\u001b[1;32m    722\u001b[0m         )\n\u001b[1;32m    723\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merrors\u001b[39;00m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: Couldn't connect to localhost:7687 (resolved to ()):\nFailed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [Errno 61] Connection refused)\nFailed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [Errno 61] Connection refused)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenerate_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_propositions, generateEdges, createGraph, get_propositions_nosplit\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrefine_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m refine\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mquery_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QueryGraph\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[0;32m~/Documents/GitHub/CypherRAG/refine_graph.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Neo4jVector\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mquery_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QueryGraph\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrefine\u001b[39m(qg: QueryGraph, entityType: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m refactor_graph(qg):\n",
      "File \u001b[0;32m~/Documents/GitHub/CypherRAG/query_graph.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m neo4j_user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneo4j\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m neo4j_password \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12345678\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 28\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mNeo4jGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneo4j_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneo4j_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneo4j_password\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m cypher_generation_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124m    You are a Cypher query generator for a Neo4j graph database. Your task is to translate user questions into precise Cypher queries. Handle both simple and multi-hop questions by following these steps:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124m    RETURN DISTINCT r2.metadata AS info1\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    135\u001b[0m cypher_generation_template2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[38;5;124m    You are a Cypher query generator for a Neo4j graph database. Your task is to translate user questions into precise Cypher queries. Handle both simple and multi-hop questions by following these steps:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124m    RETURN DISTINCT r2.metadata AS info1\u001b[39m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/graphmaker/lib/python3.11/site-packages/langchain_community/graphs/neo4j_graph.py:372\u001b[0m, in \u001b[0;36mNeo4jGraph.__init__\u001b[0;34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driver\u001b[38;5;241m.\u001b[39mverify_connectivity()\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mServiceUnavailable:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not connect to Neo4j database. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure that the url is correct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m     )\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mAuthError:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not connect to Neo4j database. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure that the username and password are correct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Could not connect to Neo4j database. Please ensure that the url is correct"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from generate_graph import get_propositions, generateEdges, createGraph, get_propositions_nosplit\n",
    "from refine_graph import refine\n",
    "from query_graph import QueryGraph\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "splits = {'train': 'squad_v2/train-00000-of-00001.parquet', 'validation': 'squad_v2/validation-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/rajpurkar/squad_v2/\" + splits[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'plain_text/train-00000-of-00001.parquet', 'validation': 'plain_text/validation-00000-of-00001.parquet'}\n",
    "df_squad = pd.read_parquet(\"hf://datasets/rajpurkar/squad/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m splits \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquad_v2/train-00000-of-00001.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquad_v2/validation-00000-of-00001.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m----> 2\u001b[0m df_squadv2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf://datasets/rajpurkar/squad_v2/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m splits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "splits = {'train': 'squad_v2/train-00000-of-00001.parquet', 'validation': 'squad_v2/validation-00000-of-00001.parquet'}\n",
    "df_squadv2 = pd.read_parquet(\"hf://datasets/rajpurkar/squad_v2/\" + splits[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the evaluation script\n",
    "\n",
    "```\n",
    "python evaluate-v2.0.py <path_to_dev-v2.0> <path_to_predictions>\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "python evaluate-v2.0.py <dev-v2.0.json> <predictions.json>\n",
    "\n",
    "python evalscripts/SQuADv2/evaluate-v2.0.py evalscripts/SQuADv2/dev-v2.0.json evalscripts/SQuADv2/predictions.json\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_squadv2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = df_squadv2['context'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propositions = []\n",
    "\n",
    "for context in context_list:\n",
    "    get_propositions(context, propositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "with open('propositions.txt', 'r') as file:\n",
    "    # Read all lines and store them in a list\n",
    "    propositions_from_file = [line.strip() for line in file]\n",
    "\n",
    "print(propositions_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(propositions_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2500 props takes 97 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-2500\n",
    "# Done\n",
    "list_of_edges = generateEdges(propositions_from_file[0:2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2500-5000\n",
    "# Done\n",
    "list_of_edges = generateEdges(propositions_from_file[2500:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5000-7500\n",
    "# Done\n",
    "list_of_edges = generateEdges(propositions_from_file[5000:7500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7500-10000\n",
    "# done\n",
    "list_of_edges = generateEdges(propositions_from_file[7500:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000-12500\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[10000:12500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12500-15000\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[12500:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15000-17500\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[15000:17500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17500-20000\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[17500:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20000-22420\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[20000:22420])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg = QueryGraph()\n",
    "my_dict = {}\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def print_qa(row):\n",
    "    \n",
    "    question = row['question']\n",
    "    questionid = row['id']\n",
    "    req = qg.get_requirements(question)\n",
    "    result = qg.answer_question(question, req.content)\n",
    "    \n",
    "    \n",
    "    if result is not None:\n",
    "    \n",
    "        model_answer = result['result']\n",
    "\n",
    "        if \"don't know the answer\" in model_answer:\n",
    "            model_answer = \"\"\n",
    "    \n",
    "        if len(row['answers']['text']) > 0:\n",
    "            real_answer = row['answers']['text'][0]\n",
    "        else:\n",
    "            real_answer = \"\\\"\\\"\"\n",
    "\n",
    "        if len(result['intermediate_steps']) > 0:\n",
    "            cypher_query = result['intermediate_steps'][0]['query']\n",
    "            context = result['intermediate_steps'][1]['context']\n",
    "       \n",
    "            if(len(context) < 1):\n",
    "            #     result = refine_query(cypher_query[6:], question)\n",
    "            #     model_answer = result['result'] \n",
    "                model_answer = \"\\\"\\\"\"\n",
    "                my_dict.update({questionid: \"\"})\n",
    "            else:\n",
    "                my_dict.update({questionid: model_answer})\n",
    "                \n",
    "        with open(\"preds2.txt\", \"a\") as preds:\n",
    "            preds.write(\"question: \" + question + \"\\n\")\n",
    "            preds.write(\"real_answer: \" + real_answer + \"\\n\")\n",
    "            preds.write(\"model_answer: \" + model_answer + \"\\n\")  \n",
    "            preds.write(\"cypher_query: \" + cypher_query + \"\\n\")\n",
    "            preds.write(\"======================\" + \"\\n\")  \n",
    "        preds.close()\n",
    "\n",
    "    else: \n",
    "        my_dict.update({questionid: \"\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df_squadv2[0:2500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions1.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[2500:5000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions2.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[5000:7500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions3.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[7500:10000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions4.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[10000:11873].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions5.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first JSON file\n",
    "with open('predictions1.json') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "# Load the second JSON file\n",
    "with open('predictions2.json') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "# Load the third JSON file\n",
    "with open('predictions3.json') as f:\n",
    "    data3 = json.load(f)\n",
    "\n",
    "# Load the fourth JSON file\n",
    "with open('predictions4.json') as f:\n",
    "    data4 = json.load(f)\n",
    "    \n",
    "# Load the fifth JSON file\n",
    "with open('predictions5.json') as f:\n",
    "    data5 = json.load(f)\n",
    "    \n",
    "# Merge the two JSON objects (assuming they are dictionaries)\n",
    "merged_data = {**data1, **data2, **data3, **data4, **data5}\n",
    "\n",
    "# Save the merged JSON to a new file\n",
    "with open('merged.json', 'w') as f:\n",
    "    json.dump(merged_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17500-20000\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[11:20].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"squadv2preds2.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg = QueryGraph()\n",
    "my_dict = {}\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def print_qa(row):\n",
    "    \n",
    "    question = row['question']\n",
    "    questionid = row['id']\n",
    "    req = qg.get_requirements(question)\n",
    "    result = qg.answer_question(question, req.content)\n",
    "    \n",
    "    if result is not None:\n",
    "    \n",
    "        model_answer = result['result']\n",
    "\n",
    "        if \"don't know the answer\" in model_answer:\n",
    "            model_answer = \"\"\n",
    "    \n",
    "        if len(row['answers']['text']) > 0:\n",
    "            real_answer = row['answers']['text'][0]\n",
    "        else:\n",
    "            real_answer = \"\\\"\\\"\"\n",
    "\n",
    "        if len(result['intermediate_steps']) > 0:\n",
    "            cypher_query = result['intermediate_steps'][0]['query']\n",
    "            context = result['intermediate_steps'][1]['context']\n",
    "       \n",
    "            if(len(context) < 1):\n",
    "            #     result = refine_query(cypher_query[6:], question)\n",
    "            #     model_answer = result['result'] \n",
    "                model_answer = \"\\\"\\\"\"\n",
    "                my_dict.update({questionid: \"\"})\n",
    "            else:\n",
    "                my_dict.update({questionid: model_answer})\n",
    "                \n",
    "        # with open(\"squadpreds5.txt\", \"a\") as preds:\n",
    "        #     preds.write(\"question: \" + question + \"\\n\")\n",
    "        #     preds.write(\"real_answer: \" + real_answer + \"\\n\")\n",
    "        #     preds.write(\"model_answer: \" + model_answer + \"\\n\")  \n",
    "        #     preds.write(\"cypher_query: \" + cypher_query + \"\\n\")\n",
    "        #     preds.write(\"======================\" + \"\\n\")  \n",
    "        # preds.close()\n",
    "\n",
    "    else: \n",
    "        my_dict.update({questionid: \"\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[0:2500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions1.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[0:2500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions2.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[2500:5000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions3.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[5000:7500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions4.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[7500:10000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions5.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[7500:11873].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions1.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df.iloc[11]\n",
    "# question = x['question']\n",
    "# print(\"question:\", question)\n",
    "# answer = x['answers']['text']\n",
    "# print(\"answer:\", answer)\n",
    "\n",
    "# qg = QueryGraph()\n",
    "# req = qg.get_requirements(question)\n",
    "# res = qg.answer_question(question, req.content)\n",
    "# res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphmaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
