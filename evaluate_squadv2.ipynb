{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SLY\\.conda\\envs\\graphmaker\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from generate_graph import get_propositions, generateEdges, createGraph, get_propositions_nosplit\n",
    "from refine_graph import refine\n",
    "from query_graph import QueryGraph\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "splits = {'train': 'squad_v2/train-00000-of-00001.parquet', 'validation': 'squad_v2/validation-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/rajpurkar/squad_v2/\" + splits[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'plain_text/train-00000-of-00001.parquet', 'validation': 'plain_text/validation-00000-of-00001.parquet'}\n",
    "df_squad = pd.read_parquet(\"hf://datasets/rajpurkar/squad/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m splits \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquad_v2/train-00000-of-00001.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquad_v2/validation-00000-of-00001.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m----> 2\u001b[0m df_squadv2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf://datasets/rajpurkar/squad_v2/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m splits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "splits = {'train': 'squad_v2/train-00000-of-00001.parquet', 'validation': 'squad_v2/validation-00000-of-00001.parquet'}\n",
    "df_squadv2 = pd.read_parquet(\"hf://datasets/rajpurkar/squad_v2/\" + splits[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the evaluation script\n",
    "\n",
    "```\n",
    "python evaluate-v2.0.py <path_to_dev-v2.0> <path_to_predictions>\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "python evaluate-v2.0.py <dev-v2.0.json> <predictions.json>\n",
    "\n",
    "python evalscripts/SQuADv2/evaluate-v2.0.py evalscripts/SQuADv2/dev-v2.0.json evalscripts/SQuADv2/predictions.json\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11873 entries, 0 to 11872\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        11873 non-null  object\n",
      " 1   title     11873 non-null  object\n",
      " 2   context   11873 non-null  object\n",
      " 3   question  11873 non-null  object\n",
      " 4   answers   11873 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 463.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = df['context'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n",
       "       'The Norman dynasty had a major political, cultural and military impact on medieval Europe and even the Near East. The Normans were famed for their martial spirit and eventually for their Christian piety, becoming exponents of the Catholic orthodoxy into which they assimilated. They adopted the Gallo-Romance language of the Frankish land they settled, their dialect becoming known as Norman, Normaund or Norman French, an important literary language. The Duchy of Normandy, which they formed by treaty with the French crown, was a great fief of medieval France, and under Richard I of Normandy was forged into a cohesive and formidable principality in feudal tenure. The Normans are noted both for their culture, such as their unique Romanesque architecture and musical traditions, and for their significant military accomplishments and innovations. Norman adventurers founded the Kingdom of Sicily under Roger II after conquering southern Italy on the Saracens and Byzantines, and an expedition on behalf of their duke, William the Conqueror, led to the Norman conquest of England at the Battle of Hastings in 1066. Norman cultural and military influence spread from these new European centres to the Crusader states of the Near East, where their prince Bohemond I founded the Principality of Antioch in the Levant, to Scotland and Wales in Great Britain, to Ireland, and to the coasts of north Africa and the Canary Islands.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propositions = []\n",
    "\n",
    "for context in context_list:\n",
    "    get_propositions(context, propositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "with open('propositions.txt', 'r') as file:\n",
    "    # Read all lines and store them in a list\n",
    "    propositions_from_file = [line.strip() for line in file]\n",
    "\n",
    "print(propositions_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(propositions_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2500 props takes 97 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-2500\n",
    "# Done\n",
    "list_of_edges = generateEdges(propositions_from_file[0:2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2500-5000\n",
    "# Done\n",
    "list_of_edges = generateEdges(propositions_from_file[2500:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5000-7500\n",
    "# Done\n",
    "list_of_edges = generateEdges(propositions_from_file[5000:7500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7500-10000\n",
    "# done\n",
    "list_of_edges = generateEdges(propositions_from_file[7500:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000-12500\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[10000:12500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12500-15000\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[12500:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15000-17500\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[15000:17500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17500-20000\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[17500:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20000-22420\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[20000:22420])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg = QueryGraph()\n",
    "my_dict = {}\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def print_qa(row):\n",
    "    \n",
    "    question = row['question']\n",
    "    questionid = row['id']\n",
    "    req = qg.get_requirements(question)\n",
    "    result = qg.answer_question(question, req.content)\n",
    "    \n",
    "    \n",
    "    if result is not None:\n",
    "    \n",
    "        model_answer = result['result']\n",
    "\n",
    "        if \"don't know the answer\" in model_answer:\n",
    "            model_answer = \"\"\n",
    "    \n",
    "        if len(row['answers']['text']) > 0:\n",
    "            real_answer = row['answers']['text'][0]\n",
    "        else:\n",
    "            real_answer = \"\\\"\\\"\"\n",
    "\n",
    "        if len(result['intermediate_steps']) > 0:\n",
    "            cypher_query = result['intermediate_steps'][0]['query']\n",
    "            context = result['intermediate_steps'][1]['context']\n",
    "       \n",
    "            if(len(context) < 1):\n",
    "            #     result = refine_query(cypher_query[6:], question)\n",
    "            #     model_answer = result['result'] \n",
    "                model_answer = \"\\\"\\\"\"\n",
    "                my_dict.update({questionid: \"\"})\n",
    "            else:\n",
    "                my_dict.update({questionid: model_answer})\n",
    "                \n",
    "        with open(\"preds2.txt\", \"a\") as preds:\n",
    "            preds.write(\"question: \" + question + \"\\n\")\n",
    "            preds.write(\"real_answer: \" + real_answer + \"\\n\")\n",
    "            preds.write(\"model_answer: \" + model_answer + \"\\n\")  \n",
    "            preds.write(\"cypher_query: \" + cypher_query + \"\\n\")\n",
    "            preds.write(\"======================\" + \"\\n\")  \n",
    "        preds.close()\n",
    "\n",
    "    else: \n",
    "        my_dict.update({questionid: \"\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df_squadv2[0:2500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions1.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[2500:5000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions2.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[5000:7500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions3.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[7500:10000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions4.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[10000:11873].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions5.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first JSON file\n",
    "with open('predictions1.json') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "# Load the second JSON file\n",
    "with open('predictions2.json') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "# Load the third JSON file\n",
    "with open('predictions3.json') as f:\n",
    "    data3 = json.load(f)\n",
    "\n",
    "# Load the fourth JSON file\n",
    "with open('predictions4.json') as f:\n",
    "    data4 = json.load(f)\n",
    "    \n",
    "# Load the fifth JSON file\n",
    "with open('predictions5.json') as f:\n",
    "    data5 = json.load(f)\n",
    "    \n",
    "# Merge the two JSON objects (assuming they are dictionaries)\n",
    "merged_data = {**data1, **data2, **data3, **data4, **data5}\n",
    "\n",
    "# Save the merged JSON to a new file\n",
    "with open('merged.json', 'w') as f:\n",
    "    json.dump(merged_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17500-20000\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[11:20].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"squadv2preds2.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg = QueryGraph()\n",
    "my_dict = {}\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def print_qa(row):\n",
    "    \n",
    "    question = row['question']\n",
    "    questionid = row['id']\n",
    "    req = qg.get_requirements(question)\n",
    "    result = qg.answer_question(question, req.content)\n",
    "    \n",
    "    if result is not None:\n",
    "    \n",
    "        model_answer = result['result']\n",
    "\n",
    "        if \"don't know the answer\" in model_answer:\n",
    "            model_answer = \"\"\n",
    "    \n",
    "        if len(row['answers']['text']) > 0:\n",
    "            real_answer = row['answers']['text'][0]\n",
    "        else:\n",
    "            real_answer = \"\\\"\\\"\"\n",
    "\n",
    "        if len(result['intermediate_steps']) > 0:\n",
    "            cypher_query = result['intermediate_steps'][0]['query']\n",
    "            context = result['intermediate_steps'][1]['context']\n",
    "       \n",
    "            if(len(context) < 1):\n",
    "            #     result = refine_query(cypher_query[6:], question)\n",
    "            #     model_answer = result['result'] \n",
    "                model_answer = \"\\\"\\\"\"\n",
    "                my_dict.update({questionid: \"\"})\n",
    "            else:\n",
    "                my_dict.update({questionid: model_answer})\n",
    "                \n",
    "        # with open(\"squadpreds5.txt\", \"a\") as preds:\n",
    "        #     preds.write(\"question: \" + question + \"\\n\")\n",
    "        #     preds.write(\"real_answer: \" + real_answer + \"\\n\")\n",
    "        #     preds.write(\"model_answer: \" + model_answer + \"\\n\")  \n",
    "        #     preds.write(\"cypher_query: \" + cypher_query + \"\\n\")\n",
    "        #     preds.write(\"======================\" + \"\\n\")  \n",
    "        # preds.close()\n",
    "\n",
    "    else: \n",
    "        my_dict.update({questionid: \"\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[0:2500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions1.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[0:2500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions2.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[2500:5000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions3.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[5000:7500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions4.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[7500:10000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions5.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[7500:11873].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions1.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df.iloc[11]\n",
    "# question = x['question']\n",
    "# print(\"question:\", question)\n",
    "# answer = x['answers']['text']\n",
    "# print(\"answer:\", answer)\n",
    "\n",
    "# qg = QueryGraph()\n",
    "# req = qg.get_requirements(question)\n",
    "# res = qg.answer_question(question, req.content)\n",
    "# res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphmaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
