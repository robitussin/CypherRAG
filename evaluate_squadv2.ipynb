{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from generate_graph import get_propositions, generateEdges, createGraph, get_propositions_nosplit\n",
    "from refine_graph import refine\n",
    "from query_graph import QueryGraph\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "splits = {'train': 'squad_v2/train-00000-of-00001.parquet', 'validation': 'squad_v2/validation-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/rajpurkar/squad_v2/\" + splits[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'plain_text/train-00000-of-00001.parquet', 'validation': 'plain_text/validation-00000-of-00001.parquet'}\n",
    "df_squad = pd.read_parquet(\"hf://datasets/rajpurkar/squad/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'squad_v2/train-00000-of-00001.parquet', 'validation': 'squad_v2/validation-00000-of-00001.parquet'}\n",
    "df_squadv2 = pd.read_parquet(\"hf://datasets/rajpurkar/squad_v2/\" + splits[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the evaluation script\n",
    "\n",
    "```\n",
    "python evaluate-v2.0.py <path_to_dev-v2.0> <path_to_predictions>\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "python evaluate-v2.0.py <dev-v2.0.json> <predictions.json>\n",
    "\n",
    "python evalscripts/SQuADv2/evaluate-v2.0.py evalscripts/SQuADv2/dev-v2.0.json evalscripts/SQuADv2/predictions.json\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = df['context'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propositions = []\n",
    "\n",
    "for context in enumerate(tqdm(context_list[0:1])):\n",
    "    get_propositions(context, propositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propositions = []\n",
    "\n",
    "for context in enumerate(tqdm(context_list)):\n",
    "    get_propositions(context, propositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "with open('propositionscount.txt', 'r') as file:\n",
    "    # Read all lines and store them in a list\n",
    "    propositions_from_file = [line.strip() for line in file]\n",
    "\n",
    "print(propositions_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(propositions_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2500 props takes 97 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-2500\n",
    "# Done\n",
    "list_of_edges = generateEdges(propositions_from_file[0:2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2500-5000\n",
    "# Done\n",
    "list_of_edges = generateEdges(propositions_from_file[2500:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5000-7500\n",
    "# Done\n",
    "list_of_edges = generateEdges(propositions_from_file[5000:7500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7500-10000\n",
    "# done\n",
    "list_of_edges = generateEdges(propositions_from_file[7500:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000-12500\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[10000:12500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12500-15000\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[12500:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15000-17500\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[15000:17500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17500-20000\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[17500:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20000-22420\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[20000:22420])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg = QueryGraph()\n",
    "my_dict = {}\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def print_qa(row):\n",
    "    \n",
    "    question = row['question']\n",
    "    questionid = row['id']\n",
    "    req = qg.get_requirements(question)\n",
    "    result = qg.answer_question(question, req.content)\n",
    "    \n",
    "    \n",
    "    if result is not None:\n",
    "    \n",
    "        model_answer = result['result']\n",
    "\n",
    "        if \"don't know the answer\" in model_answer:\n",
    "            model_answer = \"\"\n",
    "    \n",
    "        if len(row['answers']['text']) > 0:\n",
    "            real_answer = row['answers']['text'][0]\n",
    "        else:\n",
    "            real_answer = \"\\\"\\\"\"\n",
    "\n",
    "        if len(result['intermediate_steps']) > 0:\n",
    "            cypher_query = result['intermediate_steps'][0]['query']\n",
    "            context = result['intermediate_steps'][1]['context']\n",
    "       \n",
    "            if(len(context) < 1):\n",
    "            #     result = refine_query(cypher_query[6:], question)\n",
    "            #     model_answer = result['result'] \n",
    "                model_answer = \"\\\"\\\"\"\n",
    "                my_dict.update({questionid: \"\"})\n",
    "            else:\n",
    "                my_dict.update({questionid: model_answer})\n",
    "                \n",
    "        with open(\"preds2.txt\", \"a\") as preds:\n",
    "            preds.write(\"question: \" + question + \"\\n\")\n",
    "            preds.write(\"real_answer: \" + real_answer + \"\\n\")\n",
    "            preds.write(\"model_answer: \" + model_answer + \"\\n\")  \n",
    "            preds.write(\"cypher_query: \" + cypher_query + \"\\n\")\n",
    "            preds.write(\"======================\" + \"\\n\")  \n",
    "        preds.close()\n",
    "\n",
    "    else: \n",
    "        my_dict.update({questionid: \"\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df_squadv2[0:2500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions1.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[2500:5000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions2.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[5000:7500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions3.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[7500:10000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions4.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[10000:11873].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions5.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first JSON file\n",
    "with open('predictions1.json') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "# Load the second JSON file\n",
    "with open('predictions2.json') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "# Load the third JSON file\n",
    "with open('predictions3.json') as f:\n",
    "    data3 = json.load(f)\n",
    "\n",
    "# Load the fourth JSON file\n",
    "with open('predictions4.json') as f:\n",
    "    data4 = json.load(f)\n",
    "    \n",
    "# Load the fifth JSON file\n",
    "with open('predictions5.json') as f:\n",
    "    data5 = json.load(f)\n",
    "    \n",
    "# Merge the two JSON objects (assuming they are dictionaries)\n",
    "merged_data = {**data1, **data2, **data3, **data4, **data5}\n",
    "\n",
    "# Save the merged JSON to a new file\n",
    "with open('merged.json', 'w') as f:\n",
    "    json.dump(merged_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17500-20000\n",
    "# TO FOLLOW\n",
    "list_of_edges = generateEdges(propositions_from_file[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createGraph(list_of_edges):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "\n",
    "# Apply the function to each row\n",
    "df_squadv2[11:20].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"squadv2preds2.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg = QueryGraph()\n",
    "my_dict = {}\n",
    "\n",
    "# Define a function to apply to each row\n",
    "def print_qa(row):\n",
    "    \n",
    "    question = row['question']\n",
    "    questionid = row['id']\n",
    "    req = qg.get_requirements(question)\n",
    "    result = qg.answer_question(question, req.content)\n",
    "    \n",
    "    if result is not None:\n",
    "    \n",
    "        model_answer = result['result']\n",
    "\n",
    "        if \"don't know the answer\" in model_answer:\n",
    "            model_answer = \"\"\n",
    "    \n",
    "        if len(row['answers']['text']) > 0:\n",
    "            real_answer = row['answers']['text'][0]\n",
    "        else:\n",
    "            real_answer = \"\\\"\\\"\"\n",
    "\n",
    "        if len(result['intermediate_steps']) > 0:\n",
    "            cypher_query = result['intermediate_steps'][0]['query']\n",
    "            context = result['intermediate_steps'][1]['context']\n",
    "       \n",
    "            if(len(context) < 1):\n",
    "            #     result = refine_query(cypher_query[6:], question)\n",
    "            #     model_answer = result['result'] \n",
    "                model_answer = \"\\\"\\\"\"\n",
    "                my_dict.update({questionid: \"\"})\n",
    "            else:\n",
    "                my_dict.update({questionid: model_answer})\n",
    "                \n",
    "        # with open(\"squadpreds5.txt\", \"a\") as preds:\n",
    "        #     preds.write(\"question: \" + question + \"\\n\")\n",
    "        #     preds.write(\"real_answer: \" + real_answer + \"\\n\")\n",
    "        #     preds.write(\"model_answer: \" + model_answer + \"\\n\")  \n",
    "        #     preds.write(\"cypher_query: \" + cypher_query + \"\\n\")\n",
    "        #     preds.write(\"======================\" + \"\\n\")  \n",
    "        # preds.close()\n",
    "\n",
    "    else: \n",
    "        my_dict.update({questionid: \"\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[0:2500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions1.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[0:2500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions2.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[2500:5000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions3.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[5000:7500].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions4.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[7500:10000].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions5.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "# Apply the function to each row\n",
    "df[7500:11873].progress_apply(print_qa, axis=1)\n",
    "    \n",
    "with open(\"predictions1.json\", \"a\") as json_file:\n",
    "    json.dump(my_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df.iloc[11]\n",
    "# question = x['question']\n",
    "# print(\"question:\", question)\n",
    "# answer = x['answers']['text']\n",
    "# print(\"answer:\", answer)\n",
    "\n",
    "# qg = QueryGraph()\n",
    "# req = qg.get_requirements(question)\n",
    "# res = qg.answer_question(question, req.content)\n",
    "# res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphmaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
